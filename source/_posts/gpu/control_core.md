---
title: GPU control core
date: 2024-01-30 
tags: gpu
---
本篇是《通用图形处理器设计GPGPI编程模型与架构原理》的控制核心架构
本书的模型参考GPGPU-Sim
这只是理论
<!--more-->
## 指令流水线
![Alt text](pic/gpgpuarch.png)
### 前段 取指译码 
- 依据pc值从指令缓存(I-cache)中取指，经过指令译码单元，存入指令缓冲(I-buffer)
- 每个warp需要保存一个PC
### 中段 调度发射
- warp调度
- 解决数据相关，记分牌 
- 分支管理，simt堆栈
- 寄存器文件和操作数收集器
### 后段 执行和写回
- 计算
- 访存

## warp调度
因为GPGPU切换线程的开销很小，因此可以通过大量线程束并发来隐藏访存时延，线程束的并发度由硬件资源决定
不同线程束的不同指令会交织执行，同一线程束的指令顺序执行
### 基本调度策略
就绪指令的基本条件
1. 指令已取到
2. 相关性解决
3. 执行单元可用


调度策略
- 基本轮询，轮转
- 贪心策略，一直发射一个线程束的指令


### 调度优化
SIMT架构两种局部性
1. 线程束内局部性：线程束内的线程访问数据的时间局部性和空间局部性
2. 线程束间局部性：线程束间的线程访问数据的时间局部性和空间局部性
轮询策略是考虑了线程束间的局部性
贪心则考虑了线程束内的局部性

本书之后介绍了一些改进方法，没看。。。有需要再说

## 数据相关
一般的数据相关有三种
- RAW写后读
- WAW写后写
- WAR读后写
后两种没有数据传递，可以通过寄存器重命名消除
### GPGPU中的记分牌
经典的记分牌，tomasulo，ROB可以解决数据相关，实现乱序执行，但是在GPGPU中寄存器和功能单元数量多，记录其状态开销大，且GPGPU本身指令并行度高，大量无数据相关指令可以调度，因此GPGPU采用乱序执行并非必要，只做必要的数据相关检查。
**GPGPU一般为顺序执行**
重点避免RAW和WAW，WAR一般不会出现

简单的方案：
给每一个线程束寄存器分配1bit标志位，正在执行的指令写回寄存器标记为1,后续指令查询标志，若不为1则可以发射
问题：
1. 占用存储空间大
2. Volta架构，一个sm分4个block，一个block可以分16个warp，假设一条指令4个操作数，即同一时间要检查16*4个状态，不现实
### nv的实现
1. 更改编码规则
配备记分牌空间，空间区域和I-Buffer对应，（这里联系nv的sheduler，以v100为例，一个sm分4个block，每个bolck的sheduler大小为16，即一个block可以分16个warp进行调度，那区域数可以是16）每个区域分若干条目，记录当前线程束正在执行的指令，每个条目记录寄存器起始编号和数目
2. 基于读写屏障的软件计数
control codes
> 书中讲到的control codes的S好像有点问题
> 关于具体的control codes之后再看
## 线程分支
### 谓词(predicate)寄存器
gpgpu架构普遍采用显式的谓词寄存器，谓词寄存器为每个执行通道配备1bit寄存器用来控制通道是否打开
### simt堆栈
根据每个线程的谓词寄存器可以形成线程束的活跃掩码信息
![](pic/gpgpusimt1.png)
- RPC：分支汇聚点（IPDOM）PC，一般由CFG（控制流图）分析得到
- NPC：该分支内需要执行的下一条指令PC
- TOS：栈顶指针

具体分析：
![](pic/gpgpusimt2.png)
> reference：
> https://zhuanlan.zhihu.com/p/593248814
> https://zhuanlan.zhihu.com/p/636979440


### 分支屏障
simt堆栈会存在一些问题，比如死锁：
![](pic/gpgpubarrier.png)



## 线程块的分配与调度
